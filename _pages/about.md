---
permalink: /
title: "Home"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

# Bio

My name is Ge Chunjiang. I am currently a fourth year PhD candidate in Tsinghua University. With the help of foundation models, the potential of artificial intelligence has barely been tapped. I am dedicated to using AI for the benefit of human society. My current interest is working towards enabling machine learning models to understand the open world, interact with the open world using tools. Achieving this goal requires integrating technologies across large language models, AI agents, multi-modality.

æˆ‘æ˜¯è‘›æ˜¥æ±Ÿï¼Œç›®å‰æ˜¯æ¸…åå¤§å­¦å››å¹´çº§çš„åšå£«ç”Ÿã€‚åœ¨å¤§æ¨¡å‹çš„å¸®åŠ©ä¸‹ï¼Œäººå·¥æ™ºèƒ½çš„æ½œåŠ›è¿˜è¿œè¿œæ²¡æœ‰è¢«å‘æ˜ï¼Œæˆ‘è‡´åŠ›äºç”¨äººå·¥æ™ºèƒ½æ¥é€ ç¦äººç±»ç¤¾ä¼šã€‚å½“å‰çš„æˆ‘å½“å‰çš„å…´è¶£æ˜¯è‡´åŠ›äºä½¿æœºå™¨å­¦ä¹ æ¨¡å‹å¯ä»¥ç†è§£å¼€æ”¾ä¸–ç•Œï¼Œå¹¶é€šè¿‡åˆ©ç”¨å·¥å…·å’Œå¼€æ”¾ä¸–ç•Œäº¤äº’ã€‚å®ç°è¿™ä¸ªç›®æ ‡éœ€è¦å°†å¤§è¯­è¨€æ¨¡å‹ï¼ŒAI Agentï¼Œå¤šæ¨¡æ€å¤šä¸ªé¢†åŸŸçš„æŠ€æœ¯èåˆã€‚

I am now a Ph.D candidate of Department of Automation, Tsinghua University, advised by Prof. [Gao huang](http://www.gaohuang.net/). Before coming to Department of Automation, I received B.S. in Department of Physics, Tsinghua University.

æˆ‘ç›®å‰å°±è¯»äºæ¸…åå¤§å­¦è‡ªåŠ¨åŒ–ç³»ã€‚æˆ‘çš„å¯¼å¸ˆæ˜¯é»„é«˜æ•™æˆã€‚åœ¨æ¥åˆ°è‡ªåŠ¨åŒ–ç³»ä¹‹å‰ï¼Œæˆ‘åœ¨æ¸…åå¤§å­¦ç‰©ç†ç³»è·å¾—äº†å­¦å£«å­¦ä½ã€‚

If you're interested in my work or personal development, feel free to contact me. I can arrange 30 minutes per week to communicate with you. You can contact me by email.

æˆ‘æ¯å‘¨å¯ä»¥å®‰æ’30åˆ†é’Ÿçš„æ—¶é—´å’ŒåŒå­¦ä»¬äº¤æµï¼Œå¯ä»¥ç»™æˆ‘å‘é‚®ä»¶è”ç³»ã€‚

# News

- [2024/05] I am excited to announce that our project and paper, [ConvLLaVA](https://arxiv.org/abs/2405.15738), has been released. We employ a hierarchical backbone for High resolution understanding, which is efficient and effective. Welcome cooperation!
- [2023/11] I am working on an LLM project to generate data, spanning across open-source LLM, multi-modality, quantization, and deployment. I wish to release it in December.
<!-- - [2023/08] I become a contributor of project [OpenRLHF](https://github.com/OpenLLMAI/OpenRLHF/tree/main).  -->
- [2023/06] I establish a github repo for collecting papers on [foundation models](https://github.com/John-Ge/awesome-foundation-models). Welcome pull requests and collaboration. æˆ‘å»ºç«‹äº†ä¸€ä¸ªgithubä»“åº“ï¼Œæ”¶é›†äº†å…³äºåŸºç¡€æ¨¡å‹çš„ä¸€äº›è®ºæ–‡ï¼Œæ¬¢è¿å¤§å®¶è´¡çŒ®ä¸åˆä½œã€‚

# Publications

## Preprint

**ConvLLaVA: Hierarchical Backbones as Visual Encoder for Large Multimodal Models**\
Chunjiang Ge, Sijie Cheng, Ziming Wang, Jiale Yuan, Yuan Gao, Jun Song, Shiji Song, Gao Huang, Bo Zheng \
[arXiv](https://arxiv.org/abs/2405.15738) [code](https://github.com/alibaba/conv-llava)

<p align="left">
    <a href="http://arxiv.org/abs/2405.15738"> 
        <img src="https://img.shields.io/badge/arXiv-2405.15738-b31b1b.svg?logo=arXiv">
    </a>
      <a href="https://github.com/alibaba/conv-llava"> 
        <img src="https://img.shields.io/badge/Github-ConvLLaVA-b31b1b.svg?logo=GitHub">
    </a>
    <a href="https://huggingface.co/collections/ConvLLaVA/convllava-66519ef0ccdee62544bd19bf"> 
        <img src="https://img.shields.io/badge/ğŸ¤—%20Hugging%20Face-Models-ffd21e">
    </a>
    <a href="https://modelscope.cn/organization/ConvLLaVA?tab=model"> 
        <img src="https://img.shields.io/badge/ğŸ¤–%20ModelScope-Models-5f4cf2.svg">
    </a>
    <a href="https://github.com/alibaba/conv-llava/stargazers">
        <img alt="GitHub stars" src="https://img.shields.io/github/stars/alibaba/conv-llava?color=ccf" />
    </a>
</p>

**Cross-Modal Adapter for Text-Video Retrieval**\
H Jiang, J Zhang, R Huang, C Ge, Z Ni, J Lu, J Zhou, S Song, G Huang \
[arXiv](https://arXiv.org/abs/2211.09623) [code](https://github.com/LeapLabTHU/Cross-Modal-Adapter)

## Conference Papers

**On the Integration of Self-Attention and Convolution**\
Pan, Xuran, Chunjiang Ge, Rui Lu, Shiji Song, Guanfu Chen, Zeyi Huang, and Gao Huang.  \
IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022)\
[arXiv](https://arxiv.org/abs/2111.14556) [Code](https://github.com/leaplabthu/acmix)

**Causal Intervention for Human Trajectory Prediction with Cross Attention Mechanism**\
Chunjiang Ge, Shiji Song and Gao Huang. \
AAAI Conference on Artificial Intelligence (AAAI 2023)\
[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25142)

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2023</div><img src='images/causal.jpg' alt="causal" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Causal Intervention for Human Trajectory Prediction with Cross Attention Mechanism](https://ojs.aaai.org/index.php/AAAI/article/view/25142)

**Chunjiang Ge**, Shiji Song and Gao Huang. \
AAAI Conference on Artificial Intelligence (AAAI 2023)\
[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25142)

</div>
</div> -->

## Journal Papers

**Domain Adaptation via Prompt Learning**\
Chunjiang Ge, Rui Huang, Mixue Xie, Zihang Lai, Shiji Song, Shuang Li, Gao Huang.  \
arXiv:2202.06687 \
[arXiv](https://arxiv.org/abs/2202.06687) [code](https://github.com/LeapLabTHU/DAPrompt)

**Large scale air pollution prediction with deep convolutional networks**\
Gao Huang$^\ast$, Chunjiang Ge$^\ast$, Tianyu Xiong, Shiji Song, Le Yang, Baoxian Liu, Wenjun Yin and Cheng Wu.  \
Science China Information Sciences. (IFï¼š8.8) \
[Paper](https://link.springer.com/article/10.1007/s11432-020-2951-1)

---

<script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=5fymzl2m77g&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script>