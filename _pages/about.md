---
permalink: /
title: "Home"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

# Bio

My name is Ge Chunjiang. I am currently a fifth year PhD candidate in Tsinghua University. My research interest lies in Computer Vision and Multimodal Foundation Models, and the ultimate goals are towards enabling machine learning models to understand the open world, interact with the open world.

æˆ‘æ˜¯è‘›æ˜¥æ±Ÿï¼Œç›®å‰æ˜¯æ¸…åå¤§å­¦äº”å¹´çº§çš„åšå£«ç”Ÿã€‚æˆ‘å…´è¶£æ˜¯è®¡ç®—æœºè§†è§‰å’Œå¤šæ¨¡æ€åŸºç¡€æ¨¡å‹ï¼Œæœ€ç»ˆç›®æ ‡æ˜¯ä½¿æœºå™¨å­¦ä¹ æ¨¡å‹å¯ä»¥ç†è§£å¼€æ”¾ä¸–ç•Œï¼Œå¹¶å’Œå¼€æ”¾ä¸–ç•Œäº¤äº’ã€‚

I am now a Ph.D candidate of Department of Automation, Tsinghua University, advised by Prof. [Shiji Song](https://scholar.google.com/citations?user=rw6vWdcAAAAJ&hl=en) and Prof. [Gao huang](http://www.gaohuang.net/). Before coming to Department of Automation, I received B.S. in Department of Physics, Tsinghua University. **I am actively seeking postdoctoral positions and industrial opportunities.**

æˆ‘ç›®å‰å°±è¯»äºæ¸…åå¤§å­¦è‡ªåŠ¨åŒ–ç³»ã€‚æˆ‘åœ¨æ¸…åå¤§å­¦ç‰©ç†ç³»è·å¾—æ•°ç†åŸºç¡€ç§‘å­¦å­¦ä½ã€‚æˆ‘åœ¨å¯»æ±‚**åšå£«åå’Œå·¥ä¸šç•Œ**çš„æœºä¼šã€‚

If you're interested in my work or personal development, feel free to contact me. I can arrange 30 minutes per week to communicate with you. You can contact me by email.

æˆ‘æ¯å‘¨å¯ä»¥å®‰æ’30åˆ†é’Ÿçš„æ—¶é—´å’ŒåŒå­¦ä»¬äº¤æµï¼Œå¯ä»¥ç»™æˆ‘å‘é‚®ä»¶è”ç³»ã€‚å¦‚æœä½ æœ‰å¾®ä¿¡ï¼Œå¯ä»¥ [å¾®ä¿¡](https://github.com/John-Ge/John-Ge.github.io/blob/master/images/wechat.jpg) è”ç³»ã€‚
# News

- [2024/10] Awarded by National Scholarship (å›½å®¶å¥–å­¦é‡‘), Ministry of Education of China.
- [2024/05] I am excited to announce that our project and paper, [ConvLLaVA](https://arxiv.org/abs/2405.15738), has been released. We employ a hierarchical backbone for High resolution understanding, which is efficient and effective. Welcome cooperation!
<!-- - [2023/08] I become a contributor of project [OpenRLHF](https://github.com/OpenLLMAI/OpenRLHF/tree/main).  -->
- [2023/06] I establish a github repo for collecting papers on [foundation models](https://github.com/John-Ge/awesome-foundation-models). Welcome pull requests and collaborationã€‚

# Publications

## Highlight

**ConvLLaVA: Hierarchical Backbones as Visual Encoder for Large Multimodal Models**\
Chunjiang Ge, Sijie Cheng, Ziming Wang, Jiale Yuan, Yuan Gao, Jun Song, Shiji Song, Gao Huang, Bo Zheng \
**TL; DR:** We propose to employ a five stage ConvNeXt as the visual encoder of LMM to compress visual tokens, greatly improves performance on high resolution benchmarks and efficiency.\
<a href="http://arxiv.org/abs/2405.15738"> 
    <img src="https://img.shields.io/badge/arXiv-2405.15738-b31b1b.svg?logo=arXiv">
</a>
<a href="https://github.com/alibaba/conv-llava"> 
    <img src="https://img.shields.io/badge/Github-ConvLLaVA-181717.svg?logo=GitHub">
</a>
<a href="https://huggingface.co/collections/ConvLLaVA/convllava-66519ef0ccdee62544bd19bf"> 
    <img src="https://img.shields.io/badge/ğŸ¤—%20Hugging%20Face-Models-ffd21e">
</a>
<a href="https://modelscope.cn/organization/ConvLLaVA?tab=model"> 
    <img src="https://img.shields.io/badge/ğŸ¤–%20ModelScope-Models-5f4cf2.svg">
</a>
<a href="https://github.com/alibaba/conv-llava/stargazers">
    <img alt="GitHub stars" src="https://img.shields.io/github/stars/alibaba/conv-llava?color=ccf" />
</a>

**Domain Adaptation via Prompt Learning**\
Chunjiang Ge, Rui Huang, Mixue Xie, Zihang Lai, Shiji Song, Shuang Li, Gao Huang.  \
**TL; DR:** We propose a novel domain adaptation method, DAPrompt, which learns a set of domain-specific prompts to avoid information loss resulted from domain alignment.\
<a href="https://arxiv.org/abs/2202.06687"> 
    <img src="https://img.shields.io/badge/arXiv-2202.06687-b31b1b.svg?logo=arXiv">
</a>
  <a href="https://github.com/LeapLabTHU/DAPrompt"> 
    <img src="https://img.shields.io/badge/Github-DAPrompt-181717.svg?logo=GitHub">
</a>
<a href="https://github.com/LeapLabTHU/DAPrompt/stargazers">
    <img alt="GitHub stars" src="https://img.shields.io/github/stars/LeapLabTHU/DAPrompt?color=ccf" />
</a>

## MultiModal Large Language Models (MLLM)

**ConvLLaVA: Hierarchical Backbones as Visual Encoder for Large Multimodal Models**\
Chunjiang Ge, Sijie Cheng, Ziming Wang, Jiale Yuan, Yuan Gao, Jun Song, Shiji Song, Gao Huang, Bo Zheng \
[arXiv](https://arxiv.org/abs/2405.15738) [code](https://github.com/alibaba/conv-llava)

**Llava-uhd: an lmm perceiving any aspect ratio and high-resolution images**\
Ruyi Xu, Yuan Yao, Zonghao Guo, Junbo Cui, Zanlin Ni, Chunjiang Ge, Tat-Seng Chua, Zhiyuan Liu, Maosong Sun, Gao Huang.  \
[arXiv](https://arxiv.org/abs/2403.11703)

## Traditional Computer Vision

**Domain Adaptation via Prompt Learning**\
Chunjiang Ge, Rui Huang, Mixue Xie, Zihang Lai, Shiji Song, Shuang Li, Gao Huang.  \
IEEE Transactions on Neural Networks and Learning Systems (TNNLS) (IF: 10.4) \
[arXiv](https://arxiv.org/abs/2202.06687) [code](https://github.com/LeapLabTHU/DAPrompt)

**On the Integration of Self-Attention and Convolution**\
Pan, Xuran, Chunjiang Ge, Rui Lu, Shiji Song, Guanfu Chen, Zeyi Huang, and Gao Huang.  \
IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022)\
[arXiv](https://arxiv.org/abs/2111.14556) [Code](https://github.com/leaplabthu/acmix)

**Cross-Modal Adapter for Text-Video Retrieval**\
Haojun Jiang, Jianke Zhang, Rui Huang, Chunjiang Ge, Zanlin Ni, Shiji Song, Gao Huang \
Pattern Recognition (PR) (IF: 7.5) \
[arXiv](https://arXiv.org/abs/2211.09623) [code](https://github.com/LeapLabTHU/Cross-Modal-Adapter)

**Causal Intervention for Human Trajectory Prediction with Cross Attention Mechanism**\
Chunjiang Ge, Shiji Song and Gao Huang. \
AAAI Conference on Artificial Intelligence (AAAI 2023)\
[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25142)

**Large scale air pollution prediction with deep convolutional networks**\
Chunjiang Ge$^\ast$, Gao Huang, Tianyu Xiong, Shiji Song, Le Yang, Baoxian Liu, Wenjun Yin and Cheng Wu.  \
Science China Information Sciences. (IFï¼š8.8) \
[Paper](https://link.springer.com/article/10.1007/s11432-020-2951-1)

**Using human feedback to fine-tune diffusion models without any reward model**\
Kai Yang, Jian Tao, Jiafei Lyu, Chunjiang Ge, Jiaxin Chen, Weihan Shen, Xiaolong Zhu, Xiu Li.  \
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. \
[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Using_Human_Feedback_to_Fine-tune_Diffusion_Models_without_Any_Reward_CVPR_2024_paper.pdf)

**Demystify Mamba in Vision: A Linear Attention Perspective**\
Dongchen Han, Ziyi Wang, Zhuofan Xia, Yizeng Han, Yifan Pu, Chunjiang Ge, Jun Song, Shiji Song, Bo Zheng, Gao Huang.  \
[Paper](https://arxiv.org/abs/2405.16605)

---

<script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=5fymzl2m77g&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script>