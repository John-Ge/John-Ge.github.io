---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<!-- {% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}

{% include base_path %}

{% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %} -->


## Highlight

**ConvLLaVA: Hierarchical Backbones as Visual Encoder for Large Multimodal Models**\
Chunjiang Ge, Sijie Cheng, Ziming Wang, Jiale Yuan, Yuan Gao, Jun Song, Shiji Song, Gao Huang, Bo Zheng \
**TL; DR:** We propose to employ a five stage ConvNeXt as the visual encoder of LMM to compress visual tokens, greatly improves performance on high resolution benchmarks and efficiency.\
<a href="http://arxiv.org/abs/2405.15738"> 
    <img src="https://img.shields.io/badge/arXiv-2405.15738-b31b1b.svg?logo=arXiv">
</a>
<a href="https://github.com/alibaba/conv-llava"> 
    <img src="https://img.shields.io/badge/Github-ConvLLaVA-181717.svg?logo=GitHub">
</a>
<a href="https://huggingface.co/collections/ConvLLaVA/convllava-66519ef0ccdee62544bd19bf"> 
    <img src="https://img.shields.io/badge/ðŸ¤—%20Hugging%20Face-Models-ffd21e">
</a>
<a href="https://modelscope.cn/organization/ConvLLaVA?tab=model"> 
    <img src="https://img.shields.io/badge/ðŸ¤–%20ModelScope-Models-5f4cf2.svg">
</a>
<a href="https://github.com/alibaba/conv-llava/stargazers">
    <img alt="GitHub stars" src="https://img.shields.io/github/stars/alibaba/conv-llava?color=ccf" />
</a>

**Domain Adaptation via Prompt Learning**\
Chunjiang Ge, Rui Huang, Mixue Xie, Zihang Lai, Shiji Song, Shuang Li, Gao Huang.  \
**TL; DR:** We propose a novel domain adaptation method, DAPrompt, which learns a set of domain-specific prompts to avoid information loss resulted from domain alignment.\
<a href="https://arxiv.org/abs/2202.06687"> 
    <img src="https://img.shields.io/badge/arXiv-2202.06687-b31b1b.svg?logo=arXiv">
</a>
  <a href="https://github.com/LeapLabTHU/DAPrompt"> 
    <img src="https://img.shields.io/badge/Github-DAPrompt-181717.svg?logo=GitHub">
</a>
<a href="https://github.com/LeapLabTHU/DAPrompt/stargazers">
    <img alt="GitHub stars" src="https://img.shields.io/github/stars/LeapLabTHU/DAPrompt?color=ccf" />
</a>

## MultiModal Large Language Models (MLLM)

**ConvLLaVA: Hierarchical Backbones as Visual Encoder for Large Multimodal Models**\
Chunjiang Ge, Sijie Cheng, Ziming Wang, Jiale Yuan, Yuan Gao, Jun Song, Shiji Song, Gao Huang, Bo Zheng \
[arXiv](https://arxiv.org/abs/2405.15738) [code](https://github.com/alibaba/conv-llava)

**Llava-uhd: an lmm perceiving any aspect ratio and high-resolution images**\
Ruyi Xu, Yuan Yao, Zonghao Guo, Junbo Cui, Zanlin Ni, Chunjiang Ge, Tat-Seng Chua, Zhiyuan Liu, Maosong Sun, Gao Huang.  \
[Paper](https://arxiv.org/abs/2403.11703)

## Traditional Computer Vision

**Domain Adaptation via Prompt Learning**\
Chunjiang Ge, Rui Huang, Mixue Xie, Zihang Lai, Shiji Song, Shuang Li, Gao Huang.  \
IEEE Transactions on Neural Networks and Learning Systems (TNNLS) \
[arXiv](https://arxiv.org/abs/2202.06687) [code](https://github.com/LeapLabTHU/DAPrompt)

**On the Integration of Self-Attention and Convolution**\
Pan, Xuran, Chunjiang Ge, Rui Lu, Shiji Song, Guanfu Chen, Zeyi Huang, and Gao Huang.  \
IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2022)\
[arXiv](https://arxiv.org/abs/2111.14556) [Code](https://github.com/leaplabthu/acmix)

**Cross-Modal Adapter for Text-Video Retrieval**\
H Jiang, J Zhang, R Huang, C Ge, Z Ni, J Lu, J Zhou, S Song, G Huang \
[arXiv](https://arXiv.org/abs/2211.09623) [code](https://github.com/LeapLabTHU/Cross-Modal-Adapter)

**Causal Intervention for Human Trajectory Prediction with Cross Attention Mechanism**\
Chunjiang Ge, Shiji Song and Gao Huang. \
AAAI Conference on Artificial Intelligence (AAAI 2023)\
[paper](https://ojs.aaai.org/index.php/AAAI/article/view/25142)

**Large scale air pollution prediction with deep convolutional networks**\
Chunjiang Ge$^\ast$, Gao Huang, Tianyu Xiong, Shiji Song, Le Yang, Baoxian Liu, Wenjun Yin and Cheng Wu.  \
Science China Information Sciences. (IFï¼š8.8) \
[Paper](https://link.springer.com/article/10.1007/s11432-020-2951-1)

**Using human feedback to fine-tune diffusion models without any reward model**\
Kai Yang, Jian Tao, Jiafei Lyu, Chunjiang Ge, Jiaxin Chen, Weihan Shen, Xiaolong Zhu, Xiu Li.  \
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. \
[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Using_Human_Feedback_to_Fine-tune_Diffusion_Models_without_Any_Reward_CVPR_2024_paper.pdf)

**Demystify Mamba in Vision: A Linear Attention Perspective**\
Dongchen Han, Ziyi Wang, Zhuofan Xia, Yizeng Han, Yifan Pu, Chunjiang Ge, Jun Song, Shiji Song, Bo Zheng, Gao Huang.  \
[Paper](https://arxiv.org/abs/2405.16605)